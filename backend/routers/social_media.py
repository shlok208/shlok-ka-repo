from fastapi import APIRouter, Depends, HTTPException, status, Header
from typing import List, Optional, Dict, Any
import os
import requests
import httpx
import asyncio
from datetime import datetime, timedelta
from supabase import create_client, Client
from dotenv import load_dotenv
from pydantic import BaseModel
from cryptography.fernet import Fernet
import json

# Load environment variables
load_dotenv()

# Get Supabase client
supabase_url = os.getenv("SUPABASE_URL")
supabase_anon_key = os.getenv("SUPABASE_ANON_KEY")
supabase_service_key = os.getenv("SUPABASE_SERVICE_ROLE_KEY")

if not supabase_url or not supabase_anon_key:
    raise ValueError("SUPABASE_URL and SUPABASE_ANON_KEY must be set")

# Create client with anon key for user authentication
supabase: Client = create_client(supabase_url, supabase_anon_key)

# Create admin client for database operations
if supabase_service_key:
    supabase_admin: Client = create_client(supabase_url, supabase_service_key)
else:
    supabase_admin = supabase  # Fallback to anon client

# User model
class User(BaseModel):
    id: str
    email: str
    name: str
    created_at: str

def get_current_user(authorization: str = Header(None)):
    """Get current user from Supabase JWT token"""
    try:
        print(f"Authorization header: {authorization}")
        
        if not authorization or not authorization.startswith("Bearer "):
            print("No valid authorization header, using mock user")
            return User(
                id="d523ec90-d5ee-4393-90b7-8f117782fcf5",
                email="test@example.com", 
                name="Test User",
                created_at="2025-01-01T00:00:00Z"
            )
        
        # Extract token
        token = authorization.split(" ")[1]
        print(f"Token received: {token[:20]}...")
        
        # Try to get user info from Supabase using the token
        try:
            print(f"Attempting to authenticate with Supabase...")
            user_response = supabase.auth.get_user(token)
            print(f"Supabase user response: {user_response}")
            
            if user_response and hasattr(user_response, 'user') and user_response.user:
                user_data = user_response.user
                print(f"‚úÖ Authenticated user: {user_data.id} - {user_data.email}")
                return User(
                    id=user_data.id,
                    email=user_data.email or "unknown@example.com",
                    name=user_data.user_metadata.get('name', user_data.email or "Unknown User"),
                    created_at=user_data.created_at.isoformat() if hasattr(user_data.created_at, 'isoformat') else str(user_data.created_at)
                )
            else:
                print("‚ùå No user found in response, using mock user")
                return User(
                    id="d523ec90-d5ee-4393-90b7-8f117782fcf5",
                    email="test@example.com", 
                    name="Test User",
                    created_at="2025-01-01T00:00:00Z"
                )
                
        except Exception as e:
            print(f"‚ùå Supabase auth error: {e}")
            print(f"Error type: {type(e).__name__}")
            # Fallback to mock for now
            return User(
                id="d523ec90-d5ee-4393-90b7-8f117782fcf5",
                email="test@example.com", 
                name="Test User",
                created_at="2025-01-01T00:00:00Z"
            )
            
    except Exception as e:
        print(f"Authentication error: {e}")
        # Fallback to mock for now
        return User(
            id="d523ec90-d5ee-4393-90b7-8f117782fcf5",
            email="test@example.com", 
            name="Test User",
            created_at="2025-01-01T00:00:00Z"
        )

router = APIRouter(prefix="/social-media", tags=["social-media"])

def get_encryption_key():
    """Get or generate encryption key for token decryption"""
    encryption_key = os.getenv("ENCRYPTION_KEY")
    if not encryption_key:
        print("‚ö†Ô∏è No ENCRYPTION_KEY found, generating new key")
        key = Fernet.generate_key()
        encryption_key = key.decode()
        print(f"üîë Generated new encryption key: {encryption_key[:20]}...")
        print("‚ö†Ô∏è Please set this as ENCRYPTION_KEY in your environment variables")
    else:
        print(f"üîë Using existing encryption key: {encryption_key[:20]}...")
    
    return encryption_key.encode()

def decrypt_token(encrypted_token: str) -> str:
    """Decrypt access token"""
    try:
        encryption_key = get_encryption_key()
        fernet = Fernet(encryption_key)
        decrypted_token = fernet.decrypt(encrypted_token.encode()).decode()
        print(f"‚úÖ Successfully decrypted token: {decrypted_token[:20]}...")
        return decrypted_token
    except Exception as e:
        print(f"‚ùå Error decrypting token: {e}")
        # Try to use token as-is if decryption fails (for backward compatibility)
        print("üîÑ Trying to use token as-is...")
        return encrypted_token

@router.get("/latest-posts")
async def get_latest_posts(
    current_user: User = Depends(get_current_user),
    limit: int = 10
):
    """Get latest posts from all connected social media platforms"""
    try:
        print(f"üì± Fetching latest posts for user: {current_user.id}")
        
        # Get user's active connections
        response = supabase_admin.table("platform_connections").select("*").eq("user_id", current_user.id).eq("is_active", True).execute()
        connections = response.data if response.data else []
        
        print(f"üìä Found {len(connections)} active connections")
        platform_counts = {}
        for conn in connections:
            platform = conn.get('platform', '').lower()
            platform_counts[platform] = platform_counts.get(platform, 0) + 1
            print(f"üîó Connection: {conn.get('platform')} (raw) -> '{platform}' (lowercased) - {conn.get('page_name', 'Unknown')} - Active: {conn.get('is_active')}")

        print(f"üìä Platform breakdown: {platform_counts}")
        print(f"üìä All platform values: {[conn.get('platform', '') for conn in connections]}")

        if not connections:
            print("‚ö†Ô∏è No active connections found - this explains why only Instagram might be showing if there are cached Instagram posts")
        
        posts_by_platform = {}
        
        for connection in connections:
            platform = connection.get('platform', '').lower()
            print(f"üîç Processing {platform} connection: {connection.get('id')}")
            print(f"üìä Connection details: {connection}")
            
            try:
                print(f"üîç DEBUG: Processing platform: '{platform}' (type: {type(platform)}) - repr: {repr(platform)}")
                if platform == 'facebook':
                    posts = await fetch_facebook_posts(connection, limit)
                    print(f"üì± Facebook posts fetched: {len(posts) if posts else 0}")
                    # If no real posts found, add some mock data for testing
                    if not posts:
                        print(f"üîÑ No real posts found for {platform}, adding mock data for testing")
                        posts = [{
                            'id': f'mock_{platform}_1',
                            'message': f'This is a sample post from your {platform} page. This is mock data for testing purposes.',
                            'created_time': '2025-01-07T10:00:00+0000',
                            'permalink_url': f'https://facebook.com/mock_post_1',
                            'media_url': None,
                            'likes_count': 15,
                            'comments_count': 3,
                            'shares_count': 2
                        }]
                elif platform == 'instagram':
                    print(f"üîÑ Attempting to fetch Instagram posts...")
                    try:
                        posts = await fetch_instagram_posts(connection, limit)
                        print(f"üì± Instagram posts fetched: {len(posts) if posts else 0}")
                        if posts:
                            print(f"üìã Latest Instagram post: {posts[0].get('message', '')[:100]}...")
                    except Exception as instagram_error:
                        print(f"‚ùå Error fetching Instagram posts: {instagram_error}")
                        posts = []

                    # Only add mock data if there are no posts AND this is for testing
                    # For live data, we want real posts or empty array
                    if not posts:
                        print(f"‚ö†Ô∏è No real posts found for {platform} - this could mean:")
                        print(f"   - No posts exist on the account")
                        print(f"   - API permissions are insufficient")
                        print(f"   - Account is private or restricted")
                        print(f"   - Connection needs to be refreshed")
                elif platform == 'twitter':
                    posts = await fetch_twitter_posts(connection, limit)
                    print(f"üì± Twitter posts fetched: {len(posts) if posts else 0}")
                    # If no real posts found, add some mock data for testing
                    if not posts:
                        print(f"üîÑ No real posts found for {platform}, adding mock data for testing")
                        posts = [{
                            'id': f'mock_{platform}_1',
                            'message': f'This is a sample tweet from your {platform} account. This is mock data for testing purposes. #test #socialmedia',
                            'created_time': '2025-01-07T10:00:00+0000',
                            'permalink_url': f'https://twitter.com/mock_tweet_1',
                            'media_url': None,
                            'likes_count': 12,
                            'comments_count': 2,
                            'shares_count': 1
                        }]
                elif platform == 'linkedin':
                    posts = await fetch_linkedin_posts(connection, limit)
                    print(f"üì± LinkedIn posts fetched: {len(posts) if posts else 0}")
                    # If no real posts found, add some mock data for testing
                    if not posts:
                        print(f"üîÑ No real posts found for {platform}, adding mock data for testing")
                        posts = [{
                            'id': f'mock_{platform}_1',
                            'message': f'This is a sample post from your {platform} page. This is mock data for testing purposes.',
                            'created_time': '2025-01-07T10:00:00+0000',
                            'permalink_url': f'https://linkedin.com/mock_post_1',
                            'media_url': None,
                            'likes_count': 8,
                            'comments_count': 1,
                            'shares_count': 0
                        }]
                elif platform == 'youtube':
                    posts = await fetch_youtube_posts(connection, limit)
                    print(f"üì± YouTube posts fetched: {len(posts) if posts else 0}")
                    # If no real posts found, add some mock data for testing
                    if not posts:
                        print(f"üîÑ No real posts found for {platform}, adding mock data for testing")
                        posts = [{
                            'id': f'mock_{platform}_1',
                            'message': f'This is a sample video from your {platform} channel. This is mock data for testing purposes.',
                            'created_time': '2025-01-07T10:00:00+0000',
                            'permalink_url': f'https://youtube.com/mock_video_1',
                            'media_url': None,
                            'likes_count': 20,
                            'comments_count': 5,
                            'shares_count': 3
                        }]
                elif platform == 'wordpress':
                    posts = await fetch_wordpress_posts(connection, limit)
                    print(f"üì± WordPress posts fetched: {len(posts) if posts else 0}")
                    # If no real posts found, add some mock data for testing
                    if not posts:
                        print(f"üîÑ No real posts found for {platform}, adding mock data for testing")
                        posts = [{
                            'id': f'mock_{platform}_1',
                            'message': f'This is a sample blog post from your {platform} site. This is mock data for testing purposes.',
                            'created_time': '2025-01-07T10:00:00+0000',
                            'permalink_url': f'https://wordpress.com/mock_post_1',
                            'media_url': None,
                            'likes_count': 5,
                            'comments_count': 2,
                            'shares_count': 1
                        }]
                elif platform == 'google':
                    posts = await fetch_google_posts(connection, limit)
                    print(f"üì± Google posts fetched: {len(posts) if posts else 0}")
                    # If no real posts found, add some mock data for testing
                    if not posts:
                        print(f"üîÑ No real posts found for {platform}, adding mock data for testing")
                        posts = [{
                            'id': f'mock_{platform}_1',
                            'message': f'This is a sample post from your {platform} account. This is mock data for testing purposes.',
                            'created_time': '2025-01-07T10:00:00+0000',
                            'permalink_url': f'https://google.com/mock_post_1',
                            'media_url': None,
                            'likes_count': 3,
                            'comments_count': 1,
                            'shares_count': 0
                        }]
                else:
                    print(f"‚ö†Ô∏è Unsupported platform: '{platform}' - Available platforms: facebook, instagram, twitter, linkedin, youtube, wordpress, google")
                    continue
                
                if posts:
                    posts_by_platform[platform] = posts
                    print(f"‚úÖ Fetched {len(posts)} posts from {platform}")
                    print(f"üìã Posts for {platform}: {posts}")
                else:
                    print(f"‚ö†Ô∏è No posts found for {platform}")
                    
            except Exception as e:
                print(f"‚ùå Error fetching posts from {platform}: {e}")
                # Continue with other platforms even if one fails
                continue
        
        print(f"üìä Returning posts for platforms: {list(posts_by_platform.keys())}")
        print(f"üìã Final posts_by_platform keys: {list(posts_by_platform.keys())}")
        print(f"üìã Platforms with posts: {[p for p in posts_by_platform.keys() if posts_by_platform[p]]}")
        print(f"üìã Post counts by platform: {[(p, len(posts)) for p, posts in posts_by_platform.items()]}")

        result = {
            "posts": posts_by_platform,
            "total_platforms": len(posts_by_platform),
            "total_posts": sum(len(posts) for posts in posts_by_platform.values())
        }
        print(f"üìä Response summary: {result['total_platforms']} platforms, {result['total_posts']} total posts")
        return result
        
    except Exception as e:
        print(f"‚ùå Error fetching latest posts: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to fetch latest posts: {str(e)}"
        )

async def fetch_facebook_posts(connection: dict, limit: int) -> List[Dict[str, Any]]:
    """Fetch latest posts from Facebook"""
    try:
        print(f"üîç Facebook connection data: {connection}")
        access_token = decrypt_token(connection.get('access_token_encrypted', ''))
        page_id = connection.get('page_id')
        
        print(f"üìÑ Facebook page_id: {page_id}")
        print(f"üîë Facebook access_token: {access_token[:20]}...")
        
        if not page_id:
            print("‚ùå No page_id found for Facebook connection")
            return []
        
        # Try to get page access token first
        page_access_token = None
        try:
            page_check_url = f"https://graph.facebook.com/v18.0/{page_id}"
            page_params = {
                'access_token': access_token,
                'fields': 'id,name,access_token'
            }

            page_response = requests.get(page_check_url, params=page_params, timeout=10)
            print(f"üìä Facebook page check response status: {page_response.status_code}")

            if page_response.status_code == 200:
                page_data = page_response.json()
                page_access_token = page_data.get('access_token')
                print(f"‚úÖ Got page access token: {page_access_token[:20] if page_access_token else None}...")
        except Exception as page_error:
            print(f"‚ö†Ô∏è Could not get page access token: {page_error}")

        # Use page access token if available, otherwise use the connection token
        token_to_use = page_access_token or access_token
        print(f"üîë Using token: {'page' if page_access_token else 'user'} access token")

        # Try different Facebook API endpoints
        # First try posts endpoint
        url = f"https://graph.facebook.com/v18.0/{page_id}/posts"
        params = {
            'access_token': token_to_use,
            'fields': 'id,message,created_time,permalink_url,attachments{media},likes.summary(true),comments.summary(true),shares',
            'limit': limit
        }
        
        print(f"üåê Facebook API URL: {url}")
        print(f"üìã Facebook API params: {params}")
        
        response = requests.get(url, params=params, timeout=10)

        print(f"üìä Facebook API response status: {response.status_code}")

        if response.status_code == 200:
            data = response.json()
            print(f"üì± Facebook API response data: {data}")
            posts = []

            for post in data.get('data', []):
                # Extract media URL if available
                media_url = None
                if post.get('attachments', {}).get('data'):
                    attachment = post['attachments']['data'][0]
                    if attachment.get('media', {}).get('image'):
                        media_url = attachment['media']['image'].get('src')

                post_data = {
                    'id': post.get('id'),
                    'message': post.get('message', ''),
                    'created_time': post.get('created_time'),
                    'permalink_url': post.get('permalink_url'),
                    'media_url': media_url,
                    'likes_count': post.get('likes', {}).get('summary', {}).get('total_count', 0),
                    'comments_count': post.get('comments', {}).get('summary', {}).get('total_count', 0),
                    'shares_count': post.get('shares', {}).get('count', 0)
                }
                posts.append(post_data)

            print(f"‚úÖ Facebook posts processed: {len(posts)}")
            return posts
        else:
            print(f"‚ùå Facebook posts endpoint failed: {response.status_code} - {response.text}")

            # Try alternative endpoint: published_posts (might have different permissions)
            print("üîÑ Trying alternative Facebook endpoint: published_posts")
            alt_url = f"https://graph.facebook.com/v18.0/{page_id}/published_posts"
            alt_params = {
                'access_token': token_to_use,
                'fields': 'id,message,created_time,permalink_url,attachments{media},likes.summary(true),comments.summary(true),shares',
                'limit': limit
            }

            alt_response = requests.get(alt_url, params=alt_params, timeout=10)
            print(f"üìä Facebook alternative API response status: {alt_response.status_code}")

            if alt_response.status_code == 200:
                alt_data = alt_response.json()
                print(f"üì± Facebook alternative API response data: {alt_data}")
                posts = []

                for post in alt_data.get('data', []):
                    # Extract media URL if available
                    media_url = None
                    if post.get('attachments', {}).get('data'):
                        attachment = post['attachments']['data'][0]
                        if attachment.get('media', {}).get('image'):
                            media_url = attachment['media']['image'].get('src')

                    post_data = {
                        'id': post.get('id'),
                        'message': post.get('message', ''),
                        'created_time': post.get('created_time'),
                        'permalink_url': post.get('permalink_url'),
                        'media_url': media_url,
                        'likes_count': post.get('likes', {}).get('summary', {}).get('total_count', 0),
                        'comments_count': post.get('comments', {}).get('summary', {}).get('total_count', 0),
                        'shares_count': post.get('shares', {}).get('count', 0)
                    }
                    posts.append(post_data)

                print(f"‚úÖ Facebook posts processed via alternative endpoint: {len(posts)}")
                return posts
            else:
                print(f"‚ùå Facebook alternative API also failed: {alt_response.status_code} - {alt_response.text}")

                # As a last resort, try to get user posts (not page posts)
                # This might work if the user has granted user_posts permission
                print("üîÑ Trying user posts as last resort")
                user_url = f"https://graph.facebook.com/v18.0/me/posts"
                user_params = {
                    'access_token': access_token,  # Use original user token
                    'fields': 'id,message,created_time,permalink_url,attachments{media},likes.summary(true),comments.summary(true),shares',
                    'limit': limit
                }

                user_response = requests.get(user_url, params=user_params, timeout=10)
                print(f"üìä Facebook user posts API response status: {user_response.status_code}")

                if user_response.status_code == 200:
                    user_data = user_response.json()
                    print(f"üì± Facebook user posts API response data: {user_data}")
                    posts = []

                    for post in user_data.get('data', []):
                        # Extract media URL if available
                        media_url = None
                        if post.get('attachments', {}).get('data'):
                            attachment = post['attachments']['data'][0]
                            if attachment.get('media', {}).get('image'):
                                media_url = attachment['media']['image'].get('src')

                        post_data = {
                            'id': post.get('id'),
                            'message': post.get('message', ''),
                            'created_time': post.get('created_time'),
                            'permalink_url': post.get('permalink_url'),
                            'media_url': media_url,
                            'likes_count': post.get('likes', {}).get('summary', {}).get('total_count', 0),
                            'comments_count': post.get('comments', {}).get('summary', {}).get('total_count', 0),
                            'shares_count': post.get('shares', {}).get('count', 0)
                        }
                        posts.append(post_data)

                    print(f"‚úÖ Facebook user posts processed: {len(posts)}")
                    return posts
                else:
                    print(f"‚ùå Facebook user posts API also failed: {user_response.status_code} - {user_response.text}")
                    return []
            
    except Exception as e:
        print(f"‚ùå Error fetching Facebook posts: {e}")
        return []

async def fetch_instagram_posts(connection: dict, limit: int) -> List[Dict[str, Any]]:
    """Fetch latest posts from Instagram"""
    try:
        print(f"üîç Instagram connection data: {connection}")
        access_token = decrypt_token(connection.get('access_token_encrypted', ''))
        page_id = connection.get('page_id')
        
        print(f"üìÑ Instagram page_id: {page_id}")
        print(f"üîë Instagram access_token: {access_token[:20]}...")
        
        if not page_id:
            print("‚ùå No page_id found for Instagram connection")
            return []
        
        # For OAuth connections, page_id is already the Instagram Business account ID
        # For token connections, we need to look it up from Facebook Page
        instagram_account_id = page_id
        
        # Check if this is a Facebook Page ID (starts with numbers and shorter) or Instagram account ID
        # Instagram account IDs are typically longer (15+ digits) and different format
        # Facebook Page IDs are usually 10-15 digits, Instagram Business account IDs are 15+ digits
        print(f"üîç Checking page_id: {page_id} (length: {len(page_id)})")
        
        if page_id.isdigit() and len(page_id) <= 15:
            # This looks like a Facebook Page ID, need to get Instagram account
            print(f"üîÑ page_id looks like Facebook Page ID, looking up Instagram account...")
            instagram_account_url = f"https://graph.facebook.com/v18.0/{page_id}"
            instagram_account_params = {
                'access_token': access_token,
                'fields': 'instagram_business_account'
            }
            
            print(f"üåê Instagram account lookup URL: {instagram_account_url}")
            
            account_response = requests.get(instagram_account_url, params=instagram_account_params, timeout=10)
            print(f"üìä Instagram account lookup response: {account_response.status_code}")
            
            if account_response.status_code != 200:
                print(f"‚ùå Instagram account lookup error: {account_response.status_code} - {account_response.text}")
                return []
            
            account_data = account_response.json()
            print(f"üì± Instagram account data: {account_data}")
            
            instagram_business_account = account_data.get('instagram_business_account')
            if not instagram_business_account:
                print("‚ùå No Instagram Business account found for this Facebook Page")
                return []
            
            instagram_account_id = instagram_business_account.get('id')
            print(f"üìÑ Found Instagram Business account ID: {instagram_account_id}")
        else:
            # This is already an Instagram account ID (15+ digits)
            print(f"‚úÖ Using page_id as Instagram account ID: {instagram_account_id}")
        
        # Now fetch media from Instagram Graph API
        url = f"https://graph.facebook.com/v18.0/{instagram_account_id}/media"
        params = {
            'access_token': access_token,
            'fields': 'id,caption,media_type,media_url,permalink,thumbnail_url,timestamp,like_count,comments_count',
            'limit': limit
        }
        
        print(f"üåê Instagram API URL: {url}")
        print(f"üìã Instagram API params: {params}")
        
        response = requests.get(url, params=params, timeout=10)
        
        print(f"üìä Instagram API response status: {response.status_code}")
        
        if response.status_code == 200:
            data = response.json()
            print(f"üì± Instagram API response data: {data}")
            posts = []
            
            for media in data.get('data', []):
                post_data = {
                    'id': media.get('id'),
                    'message': media.get('caption', ''),
                    'created_time': media.get('timestamp'),
                    'permalink_url': media.get('permalink'),
                    'media_url': media.get('media_url') or media.get('thumbnail_url'),
                    'thumbnail_url': media.get('thumbnail_url'),
                    'media_type': media.get('media_type', 'IMAGE'),
                    'likes_count': media.get('like_count', 0),
                    'comments_count': media.get('comments_count', 0),
                    'shares_count': 0  # Instagram doesn't provide shares count
                }
                posts.append(post_data)
            
            print(f"‚úÖ Instagram posts processed: {len(posts)}")
            return posts
        else:
            print(f"‚ùå Instagram API error: {response.status_code} - {response.text}")
            return []
            
    except Exception as e:
        print(f"‚ùå Error fetching Instagram posts: {e}")
        return []

async def fetch_twitter_posts(connection: dict, limit: int) -> List[Dict[str, Any]]:
    """Fetch latest posts from Twitter using API v2"""
    try:
        print(f"üê¶ Fetching Twitter posts for connection: {connection.get('id')}")
        
        access_token = decrypt_token(connection.get('access_token_encrypted', ''))
        if not access_token:
            print("‚ùå No access token found for Twitter connection")
            return []
        
        headers = {
            'Authorization': f'Bearer {access_token}',
            'Content-Type': 'application/json'
        }
        
        # Get user's timeline tweets
        user_id = connection.get('account_id')
        if not user_id:
            print("‚ùå No account ID found for Twitter connection")
            return []
        
        # Fetch user's tweets
        tweets_url = f"https://api.twitter.com/2/users/{user_id}/tweets"
        params = {
            'max_results': limit,
            'tweet.fields': 'created_at,public_metrics,text,id,attachments',
            'expansions': 'attachments.media_keys',
            'media.fields': 'url,preview_image_url,type'
        }
        
        async with httpx.AsyncClient() as client:
            response = await client.get(tweets_url, headers=headers, params=params)
            
            if response.status_code != 200:
                print(f"‚ùå Twitter API error: {response.status_code} - {response.text}")
                return []
            
            data = response.json()
            tweets = data.get('data', [])
            media_data = data.get('includes', {}).get('media', [])
            
            # Create media lookup
            media_lookup = {media['media_key']: media for media in media_data}
            
            posts = []
            for tweet in tweets:
                # Get media for this tweet
                tweet_media = []
                if 'attachments' in tweet and 'media_keys' in tweet['attachments']:
                    for media_key in tweet['attachments']['media_keys']:
                        if media_key in media_lookup:
                            media = media_lookup[media_key]
                            tweet_media.append({
                                'url': media.get('url', ''),
                                'preview_url': media.get('preview_image_url', ''),
                                'type': media.get('type', 'photo')
                            })
                
                # Format the post
                post = {
                    'id': tweet['id'],
                    'message': tweet['text'],
                    'created_time': tweet['created_at'],
                    'permalink_url': f"https://twitter.com/{connection.get('account_name', 'user')}/status/{tweet['id']}",
                    'media_url': tweet_media[0]['url'] if tweet_media else None,
                    'media_type': tweet_media[0]['type'] if tweet_media else None,
                    'likes_count': tweet['public_metrics'].get('like_count', 0),
                    'comments_count': tweet['public_metrics'].get('reply_count', 0),
                    'shares_count': tweet['public_metrics'].get('retweet_count', 0),
                    'impressions_count': tweet['public_metrics'].get('impression_count', 0)
                }
                posts.append(post)
            
            print(f"‚úÖ Fetched {len(posts)} Twitter posts")
            return posts
            
    except Exception as e:
        print(f"‚ùå Error fetching Twitter posts: {e}")
        return []

async def fetch_linkedin_posts(connection: dict, limit: int) -> List[Dict[str, Any]]:
    """Fetch latest posts from LinkedIn personal account"""
    try:
        print(f"üîç LinkedIn connection data: {connection}")
        access_token = decrypt_token(connection.get('access_token_encrypted', ''))
        linkedin_id = connection.get('linkedin_id') or connection.get('page_id')
        
        print(f"üìÑ LinkedIn ID: {linkedin_id}")
        print(f"üîë LinkedIn access_token: {access_token[:20]}...")
        
        if not linkedin_id:
            print("‚ùå No LinkedIn ID found for LinkedIn connection")
            return []
        
        headers = {
            'Authorization': f'Bearer {access_token}',
            'Content-Type': 'application/json',
            'X-Restli-Protocol-Version': '2.0.0'
        }
        
        # Try to fetch user's shares (posts they've shared)
        try:
            print("üîÑ Attempting to fetch LinkedIn shares...")
            shares_url = f"https://api.linkedin.com/v2/shares?q=owners&owners={linkedin_id}&count={limit}"
            
            response = requests.get(shares_url, headers=headers, timeout=10)
            print(f"üìä LinkedIn shares API response status: {response.status_code}")
            
            if response.status_code == 200:
                shares_data = response.json()
                print(f"‚úÖ LinkedIn shares data: {shares_data}")
                
                posts = []
                for share in shares_data.get('elements', []):
                    # Extract share information
                    share_id = share.get('id', '')
                    created_time = share.get('created', {}).get('time', '')
                    
                    # Get share content
                    specific_content = share.get('specificContent', {})
                    share_content = specific_content.get('com.linkedin.ugc.ShareContent', {})
                    share_commentary = share_content.get('shareCommentary', {})
                    text = share_commentary.get('text', '')
                    
                    # Get engagement metrics
                    social_detail = share.get('socialDetail', {})
                    total_social_counts = social_detail.get('totalSocialCounts', {})
                    
                    post = {
                        'id': share_id,
                        'message': text,
                        'created_time': created_time,
                        'permalink_url': f'https://linkedin.com/feed/update/{share_id}',
                        'media_url': None,
                        'likes_count': total_social_counts.get('numLikes', 0),
                        'comments_count': total_social_counts.get('numComments', 0),
                        'shares_count': total_social_counts.get('numShares', 0)
                    }
                    posts.append(post)
                
                if posts:
                    print(f"‚úÖ Successfully fetched {len(posts)} LinkedIn posts")
                    return posts
                else:
                    print("‚ö†Ô∏è No shares found in LinkedIn API response")
            else:
                error_data = response.json() if response.headers.get('content-type', '').startswith('application/json') else {}
                print(f"‚ùå LinkedIn shares API error: {response.status_code} - {error_data}")
                
        except Exception as api_error:
            print(f"‚ùå LinkedIn API error: {api_error}")
        
        # If API calls fail, return empty array
        print("‚ö†Ô∏è Unable to fetch real LinkedIn posts - API permissions may be insufficient")
        print("üí° LinkedIn requires r_member_social permission to fetch user's own posts")
        print("üí° This permission is currently restricted by LinkedIn")
        return []
        
    except Exception as e:
        print(f"‚ùå Error fetching LinkedIn posts: {e}")
    return []

async def fetch_youtube_posts(connection: dict, limit: int) -> List[Dict[str, Any]]:
    """Fetch latest posts from YouTube (placeholder - requires YouTube Data API)"""
    print("‚ö†Ô∏è YouTube posts not implemented yet - requires YouTube Data API")
    return []

async def fetch_wordpress_posts(connection: dict, limit: int) -> List[Dict[str, Any]]:
    """Fetch latest posts from WordPress"""
    try:
        print(f"üîç WordPress connection data: {connection}")
        access_token = decrypt_token(connection.get('access_token_encrypted', ''))
        site_url = connection.get('page_id') or connection.get('site_url')

        print(f"üìÑ WordPress site URL: {site_url}")
        print(f"üîë WordPress access_token: {access_token[:20]}...")

        if not site_url:
            print("‚ùå No site URL found for WordPress connection")
            return []

        # Try to fetch posts from WordPress REST API
        # WordPress.com sites use different API endpoints than self-hosted
        if 'wordpress.com' in site_url:
            # WordPress.com API
            api_url = f"https://public-api.wordpress.com/rest/v1.1/sites/{site_url.replace('https://', '').replace('http://', '')}/posts"
            params = {
                'number': limit,
                'fields': 'ID,title,content,excerpt,date,URL,like_count,comment_count'
            }

            headers = {
                'Authorization': f'Bearer {access_token}'
            }

            response = requests.get(api_url, params=params, headers=headers, timeout=10)
            print(f"üìä WordPress.com API response status: {response.status_code}")

            if response.status_code == 200:
                data = response.json()
                posts = []

                for post in data.get('posts', []):
                    post_data = {
                        'id': str(post.get('ID')),
                        'message': post.get('title', ''),
                        'created_time': post.get('date'),
                        'permalink_url': post.get('URL'),
                        'media_url': None,  # Would need to extract from content
                        'likes_count': post.get('like_count', 0),
                        'comments_count': post.get('comment_count', 0),
                        'shares_count': 0  # WordPress doesn't have shares
                    }
                    posts.append(post_data)

                print(f"‚úÖ WordPress.com posts processed: {len(posts)}")
                return posts
        else:
            # Self-hosted WordPress site
            api_url = f"{site_url.rstrip('/')}/wp-json/wp/v2/posts"
            params = {
                'per_page': limit,
                '_embed': 'true'  # Include featured images
            }

            # Some WordPress sites require authentication
            headers = {}
            if access_token:
                headers['Authorization'] = f'Bearer {access_token}'

            response = requests.get(api_url, params=params, headers=headers, timeout=10)
            print(f"üìä WordPress API response status: {response.status_code}")

            if response.status_code == 200:
                data = response.json()
                posts = []

                for post in data:
                    # Extract featured image if available
                    media_url = None
                    if post.get('_embedded', {}).get('wp:featuredmedia'):
                        featured_media = post['_embedded']['wp:featuredmedia'][0]
                        media_url = featured_media.get('source_url')

                    post_data = {
                        'id': str(post.get('id')),
                        'message': post.get('title', {}).get('rendered', ''),
                        'created_time': post.get('date'),
                        'permalink_url': post.get('link'),
                        'media_url': media_url,
                        'likes_count': 0,  # WordPress core doesn't have likes by default
                        'comments_count': 0,  # Would need separate comments API call
                        'shares_count': 0
                    }
                    posts.append(post_data)

                print(f"‚úÖ WordPress posts processed: {len(posts)}")
                return posts

        print(f"‚ùå WordPress API error: {response.status_code} - {response.text}")
        return []

    except Exception as e:
        print(f"‚ùå Error fetching WordPress posts: {e}")
        return []

async def fetch_google_posts(connection: dict, limit: int) -> List[Dict[str, Any]]:
    """Fetch latest posts from Google Workspace/Blogger"""
    try:
        print(f"üîç Google connection data: {connection}")
        access_token = decrypt_token(connection.get('access_token_encrypted', ''))
        blog_id = connection.get('page_id') or connection.get('blog_id')

        print(f"üìÑ Google blog ID: {blog_id}")
        print(f"üîë Google access_token: {access_token[:20]}...")

        if not blog_id:
            print("‚ùå No blog ID found for Google connection")
            return []

        # Fetch posts from Blogger API
        api_url = f"https://www.googleapis.com/blogger/v3/blogs/{blog_id}/posts"
        params = {
            'key': os.getenv('GOOGLE_API_KEY', ''),  # You might need to set this
            'maxResults': limit,
            'fields': 'items(id,title,content,url,published,labels)'
        }

        headers = {
            'Authorization': f'Bearer {access_token}'
        }

        response = requests.get(api_url, params=params, headers=headers, timeout=10)
        print(f"üìä Google Blogger API response status: {response.status_code}")

        if response.status_code == 200:
            data = response.json()
            posts = []

            for post in data.get('items', []):
                post_data = {
                    'id': post.get('id'),
                    'message': post.get('title', ''),
                    'created_time': post.get('published'),
                    'permalink_url': post.get('url'),
                    'media_url': None,  # Would need to extract from content
                    'likes_count': 0,  # Blogger doesn't provide like counts in basic API
                    'comments_count': 0,  # Would need separate API call
                    'shares_count': 0
                }
                posts.append(post_data)

            print(f"‚úÖ Google Blogger posts processed: {len(posts)}")
            return posts
        else:
            print(f"‚ùå Google Blogger API error: {response.status_code} - {response.text}")
            return []

    except Exception as e:
        print(f"‚ùå Error fetching Google posts: {e}")
        return []

@router.get("/test")
async def test_social_media_router():
    """Test endpoint to verify social media router is working"""
    return {"message": "Social media router is working!", "status": "success"}

@router.get("/debug-connections")
async def debug_connections(
    current_user: User = Depends(get_current_user)
):
    """Debug endpoint to check connections and their data"""
    try:
        print(f"üîç Debug connections for user: {current_user.id}")
        
        # Get all connections (active and inactive)
        response = supabase_admin.table("platform_connections").select("*").eq("user_id", current_user.id).execute()
        all_connections = response.data if response.data else []
        
        # Get only active connections
        active_response = supabase_admin.table("platform_connections").select("*").eq("user_id", current_user.id).eq("is_active", True).execute()
        active_connections = active_response.data if active_response.data else []
        
        # Process connections for debugging
        debug_data = {
            "user_id": current_user.id,
            "total_connections": len(all_connections),
            "active_connections": len(active_connections),
            "all_connections": [],
            "active_connections_data": []
        }
        
        for conn in all_connections:
            conn_data = {
                "id": conn.get("id"),
                "platform": conn.get("platform"),
                "page_id": conn.get("page_id"),
                "page_name": conn.get("page_name"),
                "is_active": conn.get("is_active"),
                "has_access_token": bool(conn.get("access_token_encrypted")),
                "connection_status": conn.get("connection_status"),
                "connected_at": conn.get("connected_at")
            }
            debug_data["all_connections"].append(conn_data)
        
        for conn in active_connections:
            conn_data = {
                "id": conn.get("id"),
                "platform": conn.get("platform"),
                "page_id": conn.get("page_id"),
                "page_name": conn.get("page_name"),
                "is_active": conn.get("is_active"),
                "has_access_token": bool(conn.get("access_token_encrypted")),
                "connection_status": conn.get("connection_status"),
                "connected_at": conn.get("connected_at")
            }
            debug_data["active_connections_data"].append(conn_data)
        
        return debug_data
        
    except Exception as e:
        print(f"‚ùå Error in debug connections: {e}")
        return {"error": str(e), "user_id": current_user.id}

@router.post("/twitter/post")
async def post_to_twitter(
    request: dict,
    current_user: User = Depends(get_current_user)
):
    """Post content to Twitter"""
    try:
        print(f"üê¶ Posting to Twitter for user: {current_user.id}")
        
        text = request.get('text', '')
        media_ids = request.get('media_ids', [])
        
        if not text:
            raise HTTPException(status_code=400, detail="Text content is required")
        
        # Get user's Twitter connection
        response = supabase_admin.table("platform_connections").select("*").eq("user_id", current_user.id).eq("platform", "twitter").eq("is_active", True).execute()
        
        if not response.data:
            raise HTTPException(status_code=404, detail="No active Twitter connection found")
        
        connection = response.data[0]
        access_token = decrypt_token(connection.get('access_token_encrypted', ''))
        
        if not access_token:
            raise HTTPException(status_code=400, detail="Invalid Twitter access token")
        
        headers = {
            'Authorization': f'Bearer {access_token}',
            'Content-Type': 'application/json'
        }
        
        # Prepare tweet data
        tweet_data = {
            'text': text
        }
        
        if media_ids:
            tweet_data['media'] = {
                'media_ids': media_ids
            }
        
        # Post to Twitter
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "https://api.twitter.com/2/tweets",
                headers=headers,
                json=tweet_data
            )
            
            if response.status_code != 201:
                print(f"‚ùå Twitter API error: {response.status_code} - {response.text}")
                raise HTTPException(status_code=400, detail=f"Failed to post to Twitter: {response.text}")
            
            result = response.json()
            print(f"‚úÖ Posted to Twitter: {result}")
            
            return {
                "success": True,
                "tweet_id": result['data']['id'],
                "text": result['data']['text']
            }
            
    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå Error posting to Twitter: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to post to Twitter: {str(e)}")


@router.get("/platform-stats")
async def get_platform_stats(authorization: str = Header(None)):
    """Get platform-specific stats for connected accounts (parallel processing)"""
    try:
        print("üîç Platform stats endpoint called")
        
        if not authorization or not authorization.startswith("Bearer "):
            raise HTTPException(status_code=401, detail="Missing or invalid authorization header")
        
        token = authorization.split(" ")[1]
        
        # Get user from token
        user_response = supabase.auth.get_user(token)
        if not user_response.user:
            raise HTTPException(status_code=401, detail="Invalid token")
        
        user_id = user_response.user.id
        print(f"üë§ User ID: {user_id}")
        
        # Get all connections for the user
        connections_response = supabase_admin.table("platform_connections").select("*").eq("user_id", user_id).execute()
        all_connections = connections_response.data
        
        # Filter to only Instagram and Facebook
        connections = [
            conn for conn in all_connections 
            if conn.get("platform", "").lower() in ["instagram", "facebook"]
        ]
        
        print(f"üîó Found {len(all_connections)} total connections, {len(connections)} Instagram/Facebook connections")
        
        if not connections:
            print("‚ùå No Instagram or Facebook connections found")
            return {}
        
        # Helper function to fetch stats for a single connection
        async def fetch_stats_for_connection(connection: dict) -> tuple:
            """Fetch stats for Instagram or Facebook connection. Returns (platform, stats_dict) or (platform, None) on error."""
            platform = connection.get("platform", "").lower()
            access_token_encrypted = connection.get("access_token_encrypted")
            page_id = connection.get("page_id")
            
            print(f"üì± Processing {platform} connection - page_id: {page_id}")
            
            if not access_token_encrypted:
                print(f"‚ùå No encrypted access token for {platform}")
                return (platform, None)
                
            # Decrypt the access token
            try:
                access_token = decrypt_token(access_token_encrypted)
                print(f"üîë Decrypted access token for {platform}: {access_token[:20]}...")
            except Exception as e:
                print(f"‚ùå Failed to decrypt access token for {platform}: {e}")
                return (platform, None)
            
            try:
                async with httpx.AsyncClient(timeout=httpx.Timeout(10.0)) as client:
                    if platform == "instagram":
                        # Get Instagram account info
                        instagram_url = f"https://graph.facebook.com/v18.0/{page_id}"
                        params = {
                            "fields": "followers_count,media_count",
                            "access_token": access_token
                        }
                        
                        print(f"üì∏ Fetching Instagram stats from: {instagram_url}")
                        response = await client.get(instagram_url, params=params)
                        print(f"üì∏ Instagram API response: {response.status_code}")
                        
                        if response.status_code == 200:
                            data = response.json()
                            print(f"üì∏ Instagram data: {data}")
                            return (platform, {
                                "followers_count": data.get("followers_count", 0),
                                "media_count": data.get("media_count", 0)
                            })
                        else:
                            print(f"‚ùå Instagram API error: {response.text}")
                            return (platform, None)
                    
                    elif platform == "facebook":
                        # Get Facebook page info
                        facebook_url = f"https://graph.facebook.com/v18.0/{page_id}"
                        params = {
                            "fields": "fan_count,name",
                            "access_token": access_token
                        }
                        
                        print(f"üìò Fetching Facebook stats from: {facebook_url}")
                        response = await client.get(facebook_url, params=params)
                        print(f"üìò Facebook API response: {response.status_code}")
                        
                        if response.status_code == 200:
                            data = response.json()
                            print(f"üìò Facebook data: {data}")
                            return (platform, {
                                "fan_count": data.get("fan_count", 0),
                                "page_name": data.get("name", "")
                            })
                        else:
                            print(f"‚ùå Facebook API error: {response.text}")
                            return (platform, None)
                    else:
                        print(f"‚ö†Ô∏è Unsupported platform for stats (should not reach here): {platform}")
                        return (platform, None)
                            
            except Exception as e:
                print(f"‚ùå Error fetching stats for {platform}: {e}")
                return (platform, None)
        
        # Process all connections in parallel
        print(f"üöÄ Starting parallel stats fetch for {len(connections)} connections...")
        start_time = datetime.now()
        
        tasks = [fetch_stats_for_connection(conn) for conn in connections]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        elapsed_time = (datetime.now() - start_time).total_seconds()
        print(f"‚úÖ Parallel stats fetch completed in {elapsed_time:.2f} seconds")
        
        # Aggregate results
        platform_stats = {}
        for result in results:
            # Handle exceptions
            if isinstance(result, Exception):
                print(f"‚ùå Stats task failed with exception: {result}")
                continue
            
            platform, stats = result
            if stats:
                platform_stats[platform] = stats

        print(f"üìä Final platform stats: {platform_stats}")
        return platform_stats

    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå Error getting platform stats: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to get platform stats: {str(e)}")


@router.get("/post-comments/{platform}/{post_id}")
async def get_post_comments(
    platform: str,
    post_id: str,
    current_user: User = Depends(get_current_user)
):
    """Get comments for a specific post"""
    try:
        print(f"üí¨ Getting comments for {platform} post: {post_id}")

        # Get user's connection for the platform
        response = supabase_admin.table("platform_connections").select("*").eq("user_id", current_user.id).eq("platform", platform.lower()).eq("is_active", True).execute()

        if not response.data:
            raise HTTPException(status_code=404, detail=f"No active {platform} connection found")

        connection = response.data[0]
        access_token = decrypt_token(connection.get('access_token_encrypted', ''))

        comments = []

        if platform.lower() == 'facebook':
            # Facebook comments endpoint
            url = f"https://graph.facebook.com/v18.0/{post_id}/comments"
            params = {
                'access_token': access_token,
                'fields': 'id,message,created_time,from{name,id,picture},likes.summary(true)',
                'limit': 50  # Limit to first 50 comments
            }

            print(f"üîç Facebook API call: {url}")
            print(f"üîë Access token exists: {bool(access_token)}")

            response = requests.get(url, params=params, timeout=10)

            print(f"üì° Facebook API response: {response.status_code}")

            if response.status_code == 200:
                data = response.json()
                for comment in data.get('data', []):
                    comment_data = {
                        'id': comment.get('id'),
                        'text': comment.get('message', ''),
                        'created_time': comment.get('created_time'),
                        'author': comment.get('from', {}).get('name', 'Unknown'),
                        'author_id': comment.get('from', {}).get('id'),
                        'author_picture': comment.get('from', {}).get('picture', {}).get('data', {}).get('url'),
                        'likes_count': comment.get('likes', {}).get('summary', {}).get('total_count', 0)
                    }
                    comments.append(comment_data)

        elif platform.lower() == 'instagram':
            # Instagram comments endpoint
            url = f"https://graph.facebook.com/v18.0/{post_id}/comments"
            params = {
                'access_token': access_token,
                'fields': 'id,text,timestamp,username,likes_count',
                'limit': 50
            }

            response = requests.get(url, params=params, timeout=10)

            if response.status_code == 200:
                data = response.json()
                for comment in data.get('data', []):
                    comment_data = {
                        'id': comment.get('id'),
                        'text': comment.get('text', ''),
                        'created_time': comment.get('timestamp'),
                        'author': comment.get('username', 'Unknown'),
                        'author_id': comment.get('username'),
                        'likes_count': comment.get('likes_count', 0)
                    }
                    comments.append(comment_data)

        elif platform.lower() == 'linkedin':
            # LinkedIn doesn't provide comments API in the same way
            # This is a placeholder - LinkedIn API for comments is more complex
            comments = []

        print(f"‚úÖ Retrieved {len(comments)} comments for {platform} post {post_id}")
        return {"comments": comments, "count": len(comments)}

    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå Error getting post comments: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to get post comments: {str(e)}")
